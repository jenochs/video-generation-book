{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenochs/video-generation-book/blob/main/notebooks/hunyuan_colab_a100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# HunyuanVideo on Google Colab A100\n",
        "\n",
        "**Generate high-quality videos using Tencent's HunyuanVideo model on Google Colab A100 GPU**\n",
        "\n",
        "ðŸš€ **What you'll learn:**\n",
        "- Run the 13B parameter HunyuanVideo model on Colab A100 (40GB)\n",
        "- Optimize memory usage for large-scale video generation\n",
        "- Generate videos up to 15 seconds with advanced prompting\n",
        "- Export and download high-quality video results\n",
        "\n",
        "âš¡ **Requirements:**\n",
        "- Google Colab Pro+ with A100 GPU access\n",
        "- ~20-30 minutes for complete setup\n",
        "- Google Drive for video storage (optional)\n",
        "\n",
        "ðŸ“š **From the Book:** *Hands-On Video Generation with AI* - Chapter 3: Advanced Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-header"
      },
      "source": [
        "## ðŸ”§ 1. Environment Setup & GPU Verification\n",
        "\n",
        "First, let's verify we have an A100 GPU and configure the environment for optimal performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability and specifications\n",
        "!nvidia-smi\n",
        "\n",
        "# Verify we have A100 access\n",
        "import subprocess\n",
        "result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], \n",
        "                       capture_output=True, text=True)\n",
        "print(\"\\nðŸ–¥ï¸ GPU Information:\")\n",
        "gpu_info = result.stdout.strip().split(', ')\n",
        "if len(gpu_info) >= 2:\n",
        "    gpu_name, gpu_memory = gpu_info[0], int(gpu_info[1])\n",
        "    print(f\"   GPU: {gpu_name}\")\n",
        "    print(f\"   Memory: {gpu_memory:,} MB ({gpu_memory/1024:.1f} GB)\")\n",
        "    \n",
        "    if \"A100\" in gpu_name and gpu_memory >= 40000:\n",
        "        print(\"   âœ… Perfect! A100 40GB detected - optimal for HunyuanVideo\")\n",
        "    elif \"A100\" in gpu_name:\n",
        "        print(\"   âš ï¸ A100 detected but check memory - may need optimization\")\n",
        "    else:\n",
        "        print(\"   âŒ Warning: A100 GPU recommended for best performance\")\n",
        "        print(\"   ðŸ’¡ Consider upgrading to Colab Pro+ for A100 access\")\n",
        "else:\n",
        "    print(\"   âŒ Unable to detect GPU information\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "env-config"
      },
      "outputs": [],
      "source": [
        "# Configure environment for maximum memory efficiency\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Essential memory optimizations for A100 40GB\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # Async for better performance\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # Avoid warnings\n",
        "\n",
        "# Enable optimized math operations\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "print(\"ðŸ”§ Environment configured for A100 optimization\")\n",
        "print(f\"   PyTorch version: {torch.__version__}\")\n",
        "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"   GPU count: {torch.cuda.device_count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install-header"
      },
      "source": [
        "## ðŸ“¦ 2. Install Dependencies\n",
        "\n",
        "Install the latest versions of required libraries optimized for HunyuanVideo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-pytorch"
      },
      "outputs": [],
      "source": [
        "# Install PyTorch with CUDA 12.1 support (optimized for A100)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-diffusers"
      },
      "outputs": [],
      "source": [
        "# Install HunyuanVideo dependencies\n",
        "!pip install diffusers[torch]>=0.33.1\n",
        "!pip install transformers>=4.52.4\n",
        "!pip install accelerate safetensors\n",
        "!pip install xformers  # Critical for memory efficiency\n",
        "!pip install imageio-ffmpeg  # For video processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-videogenbook"
      },
      "outputs": [],
      "source": [
        "# Install the videogenbook package\n",
        "!pip install git+https://github.com/jenochs/video-generation-book.git\n",
        "\n",
        "# Verify installation\n",
        "import videogenbook\n",
        "print(f\"âœ… videogenbook v{videogenbook.__version__} installed successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "memory-header"
      },
      "source": [
        "## ðŸ§  3. Memory Monitoring & Optimization\n",
        "\n",
        "Set up memory monitoring and configure HunyuanVideo for A100 40GB constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "memory-utils"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "from typing import Dict, Any\n",
        "\n",
        "def get_gpu_memory() -> Dict[str, float]:\n",
        "    \"\"\"Get current GPU memory usage in GB.\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        return {\"total\": 0, \"used\": 0, \"free\": 0}\n",
        "    \n",
        "    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "    cached = torch.cuda.memory_reserved() / 1024**3\n",
        "    free = total - cached\n",
        "    \n",
        "    return {\n",
        "        \"total\": total,\n",
        "        \"allocated\": allocated,\n",
        "        \"cached\": cached,\n",
        "        \"free\": free\n",
        "    }\n",
        "\n",
        "def print_memory_status(stage: str = \"\"):\n",
        "    \"\"\"Print current memory status.\"\"\"\n",
        "    mem = get_gpu_memory()\n",
        "    print(f\"ðŸ§  GPU Memory {stage}:\")\n",
        "    print(f\"   Total: {mem['total']:.1f} GB\")\n",
        "    print(f\"   Allocated: {mem['allocated']:.1f} GB\")\n",
        "    print(f\"   Cached: {mem['cached']:.1f} GB\") \n",
        "    print(f\"   Free: {mem['free']:.1f} GB\")\n",
        "    \n",
        "    # Memory warnings\n",
        "    if mem['free'] < 10:\n",
        "        print(\"   âš ï¸ Low memory - consider reducing resolution/frames\")\n",
        "    elif mem['free'] < 20:\n",
        "        print(\"   âœ… Sufficient memory for standard generation\")\n",
        "    else:\n",
        "        print(\"   ðŸš€ Excellent memory - can use higher quality settings\")\n",
        "\n",
        "def cleanup_memory():\n",
        "    \"\"\"Cleanup GPU memory.\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "# Initial memory check\n",
        "print_memory_status(\"(Initial)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-header"
      },
      "source": [
        "## ðŸ¤– 4. Load HunyuanVideo Model\n",
        "\n",
        "Load the HunyuanVideo model with A100-optimized settings for 40GB memory constraint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load-model"
      },
      "outputs": [],
      "source": [
        "from diffusers import HunyuanVideoPipeline\n",
        "import torch\n",
        "import time\n",
        "\n",
        "print(\"ðŸ”„ Loading HunyuanVideo model (this may take 5-10 minutes)...\")\n",
        "print(\"ðŸ“¥ Downloading ~26GB of model weights...\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    # Load with aggressive memory optimization for A100 40GB\n",
        "    pipe = HunyuanVideoPipeline.from_pretrained(\n",
        "        \"hunyuanvideo-community/HunyuanVideo\",  # Fixed: Use community diffusers version\n",
        "        torch_dtype=torch.float16,  # Use FP16 for memory efficiency\n",
        "        use_safetensors=True,\n",
        "        # variant=\"fp16\",  # REMOVED: Community model doesn't have fp16 variants\n",
        "        low_cpu_mem_usage=True,     # Minimize CPU memory during loading\n",
        "    )\n",
        "    \n",
        "    print(\"\\nðŸ”§ Applying A100 optimizations...\")\n",
        "    \n",
        "    # Essential memory optimizations for 40GB constraint\n",
        "    pipe.enable_sequential_cpu_offload()  # Most aggressive memory optimization\n",
        "    pipe.vae.enable_tiling()              # Reduce VAE memory usage\n",
        "    pipe.vae.enable_slicing()             # Further VAE optimization\n",
        "    \n",
        "    # Enable memory-efficient attention if available\n",
        "    try:\n",
        "        pipe.enable_xformers_memory_efficient_attention()\n",
        "        print(\"   âœ… xFormers memory-efficient attention enabled\")\n",
        "    except ImportError:\n",
        "        print(\"   âš ï¸ xFormers not available - using default attention\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âš ï¸ xFormers setup issue: {e}\")\n",
        "    \n",
        "    # Configure scheduler for memory efficiency\n",
        "    if hasattr(pipe.scheduler, 'enable_low_mem_usage'):\n",
        "        pipe.scheduler.enable_low_mem_usage = True\n",
        "    \n",
        "    load_time = time.time() - start_time\n",
        "    print(f\"\\nâœ… HunyuanVideo loaded successfully in {load_time:.1f}s\")\n",
        "    print(\"ðŸŽ¬ Ready for video generation!\")\n",
        "    \n",
        "    print_memory_status(\"(After model loading)\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to load HunyuanVideo: {str(e)}\")\n",
        "    print(\"\\nðŸ” Troubleshooting steps:\")\n",
        "    print(\"1. Ensure you have A100 GPU access\")\n",
        "    print(\"2. Check available disk space (need ~30GB)\")\n",
        "    print(\"3. Restart runtime and try again\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "generation-header"
      },
      "source": [
        "## ðŸŽ¬ 5. Generate Your First Video\n",
        "\n",
        "Generate a test video to verify everything is working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test-generation"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Video, display\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(\"/content/videos\", exist_ok=True)\n",
        "\n",
        "# Test generation with A100-optimized settings\n",
        "print(\"ðŸŽ¬ Generating test video...\")\n",
        "prompt = \"A majestic golden eagle soaring over snow-capped mountains at sunset, cinematic camera movement\"\n",
        "\n",
        "try:\n",
        "    # Generate with optimized settings for A100 40GB\n",
        "    video_frames = pipe(\n",
        "        prompt=prompt,\n",
        "        height=544,           # Optimized for A100 memory\n",
        "        width=960,            # 16:9 aspect ratio\n",
        "        num_frames=32,        # Shorter for memory efficiency\n",
        "        guidance_scale=6.0,   # Good quality/memory balance\n",
        "        num_inference_steps=25,  # Faster generation\n",
        "        generator=torch.Generator(device=\"cuda\").manual_seed(42)\n",
        "    ).frames[0]\n",
        "    \n",
        "    # Save video\n",
        "    output_path = \"/content/videos/test_video.mp4\"\n",
        "    with imageio.get_writer(output_path, fps=8, codec='h264') as writer:\n",
        "        for frame in video_frames:\n",
        "            writer.append_data(frame)\n",
        "    \n",
        "    print(f\"âœ… Video saved to: {output_path}\")\n",
        "    \n",
        "    # Display the video\n",
        "    display(Video(output_path, width=600))\n",
        "    \n",
        "    print_memory_status(\"(After generation)\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Generation failed: {str(e)}\")\n",
        "    cleanup_memory()\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion-header"
      },
      "source": [
        "## ðŸŽ‰ Success!\n",
        "\n",
        "If you've made it this far, you've successfully:\n",
        "- âœ… Loaded the 13B parameter HunyuanVideo model on Colab A100\n",
        "- âœ… Optimized for 40GB memory constraints\n",
        "- âœ… Generated your first AI video!\n",
        "\n",
        "### ðŸš€ Next Steps:\n",
        "1. Experiment with different prompts\n",
        "2. Try different resolutions and frame counts\n",
        "3. Explore the full videogenbook package\n",
        "\n",
        "### ðŸ’¡ Pro Tips:\n",
        "- Use detailed, descriptive prompts\n",
        "- Include camera movement descriptions\n",
        "- Monitor memory usage with `print_memory_status()`\n",
        "- Clean up memory between generations with `cleanup_memory()`\n",
        "\n",
        "**Happy video generating! ðŸŽ¬âœ¨**"
      ]
    }
  ]
}