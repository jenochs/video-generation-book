{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenochs/video-generation-book/blob/main/notebooks/hunyuan_colab_a100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# HunyuanVideo on Google Colab A100\n",
        "\n",
        "**Generate high-quality videos using Tencent's HunyuanVideo model on Google Colab A100 GPU**\n",
        "\n",
        "üöÄ **What you'll learn:**\n",
        "- Run the 13B parameter HunyuanVideo model on Colab A100 (40GB)\n",
        "- Optimize memory usage for large-scale video generation\n",
        "- Generate videos up to 15 seconds with advanced prompting\n",
        "- Export and download high-quality video results\n",
        "\n",
        "‚ö° **Requirements:**\n",
        "- Google Colab Pro+ with A100 GPU access\n",
        "- ~20-30 minutes for complete setup\n",
        "- Google Drive for video storage (optional)\n",
        "\n",
        "üìö **From the Book:** *Hands-On Video Generation with AI* - Chapter 3: Advanced Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-header"
      },
      "source": [
        "## üîß 1. Environment Setup & GPU Verification\n",
        "\n",
        "First, let's verify we have an A100 GPU and configure the environment for optimal performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gpu-check",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba7b062-0504-4f93-fbad-72a5e21cfb8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun  8 17:07:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             48W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "üñ•Ô∏è GPU Information:\n",
            "   GPU: NVIDIA A100-SXM4-40GB\n",
            "   Memory: 40,960 MB (40.0 GB)\n",
            "   ‚úÖ Perfect! A100 40GB detected - optimal for HunyuanVideo\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability and specifications\n",
        "!nvidia-smi\n",
        "\n",
        "# Verify we have A100 access\n",
        "import subprocess\n",
        "result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'],\n",
        "                       capture_output=True, text=True)\n",
        "print(\"\\nüñ•Ô∏è GPU Information:\")\n",
        "gpu_info = result.stdout.strip().split(', ')\n",
        "if len(gpu_info) >= 2:\n",
        "    gpu_name, gpu_memory = gpu_info[0], int(gpu_info[1])\n",
        "    print(f\"   GPU: {gpu_name}\")\n",
        "    print(f\"   Memory: {gpu_memory:,} MB ({gpu_memory/1024:.1f} GB)\")\n",
        "\n",
        "    if \"A100\" in gpu_name and gpu_memory >= 40000:\n",
        "        print(\"   ‚úÖ Perfect! A100 40GB detected - optimal for HunyuanVideo\")\n",
        "    elif \"A100\" in gpu_name:\n",
        "        print(\"   ‚ö†Ô∏è A100 detected but check memory - may need optimization\")\n",
        "    else:\n",
        "        print(\"   ‚ùå Warning: A100 GPU recommended for best performance\")\n",
        "        print(\"   üí° Consider upgrading to Colab Pro+ for A100 access\")\n",
        "else:\n",
        "    print(\"   ‚ùå Unable to detect GPU information\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "env-config"
      },
      "outputs": [],
      "source": [
        "# Configure environment for maximum memory efficiency\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Essential memory optimizations for A100 40GB\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # Async for better performance\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # Avoid warnings\n",
        "\n",
        "# Enable optimized math operations\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "print(\"üîß Environment configured for A100 optimization\")\n",
        "print(f\"   PyTorch version: {torch.__version__}\")\n",
        "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"   GPU count: {torch.cuda.device_count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install-header"
      },
      "source": [
        "## üì¶ 2. Install Dependencies\n",
        "\n",
        "Install the latest versions of required libraries optimized for HunyuanVideo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-pytorch"
      },
      "outputs": [],
      "source": [
        "# Install PyTorch with CUDA 12.1 support (optimized for A100)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-diffusers"
      },
      "outputs": [],
      "source": [
        "# Install HunyuanVideo dependencies\n",
        "!pip install diffusers[torch]>=0.33.1\n",
        "!pip install transformers>=4.52.4\n",
        "!pip install accelerate safetensors\n",
        "!pip install xformers  # Critical for memory efficiency\n",
        "!pip install imageio-ffmpeg  # For video processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-videogenbook"
      },
      "outputs": [],
      "source": [
        "# Install the videogenbook package\n",
        "!pip install git+https://github.com/jenochs/video-generation-book.git\n",
        "\n",
        "# Verify installation\n",
        "import videogenbook\n",
        "print(f\"‚úÖ videogenbook v{videogenbook.__version__} installed successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "memory-header"
      },
      "source": [
        "## üß† 3. Memory Monitoring & Optimization\n",
        "\n",
        "Set up memory monitoring and configure HunyuanVideo for A100 40GB constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "memory-utils"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "from typing import Dict, Any\n",
        "\n",
        "def get_gpu_memory() -> Dict[str, float]:\n",
        "    \"\"\"Get current GPU memory usage in GB.\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        return {\"total\": 0, \"used\": 0, \"free\": 0}\n",
        "\n",
        "    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "    cached = torch.cuda.memory_reserved() / 1024**3\n",
        "    free = total - cached\n",
        "\n",
        "    return {\n",
        "        \"total\": total,\n",
        "        \"allocated\": allocated,\n",
        "        \"cached\": cached,\n",
        "        \"free\": free\n",
        "    }\n",
        "\n",
        "def print_memory_status(stage: str = \"\"):\n",
        "    \"\"\"Print current memory status.\"\"\"\n",
        "    mem = get_gpu_memory()\n",
        "    print(f\"üß† GPU Memory {stage}:\")\n",
        "    print(f\"   Total: {mem['total']:.1f} GB\")\n",
        "    print(f\"   Allocated: {mem['allocated']:.1f} GB\")\n",
        "    print(f\"   Cached: {mem['cached']:.1f} GB\")\n",
        "    print(f\"   Free: {mem['free']:.1f} GB\")\n",
        "\n",
        "    # Memory warnings\n",
        "    if mem['free'] < 10:\n",
        "        print(\"   ‚ö†Ô∏è Low memory - consider reducing resolution/frames\")\n",
        "    elif mem['free'] < 20:\n",
        "        print(\"   ‚úÖ Sufficient memory for standard generation\")\n",
        "    else:\n",
        "        print(\"   üöÄ Excellent memory - can use higher quality settings\")\n",
        "\n",
        "def cleanup_memory():\n",
        "    \"\"\"Cleanup GPU memory.\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "# Initial memory check\n",
        "print_memory_status(\"(Initial)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-header"
      },
      "source": [
        "## ü§ñ 4. Load HunyuanVideo Model\n",
        "\n",
        "Load the HunyuanVideo model with A100-optimized settings for 40GB memory constraint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "load-model"
      },
      "outputs": [],
      "source": [
        "from diffusers import HunyuanVideoPipeline\n",
        "import torch\n",
        "import time\n",
        "\n",
        "print(\"üîÑ Loading HunyuanVideo model (this may take 5-10 minutes)...\")\n",
        "print(\"üì• Downloading ~26GB of model weights...\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    # Load with aggressive memory optimization for A100 40GB\n",
        "    pipe = HunyuanVideoPipeline.from_pretrained(\n",
        "        \"hunyuanvideo-community/HunyuanVideo\",  # Fixed: Use community diffusers version\n",
        "        torch_dtype=torch.float16,  # Use FP16 for memory efficiency\n",
        "        use_safetensors=True,\n",
        "        # variant=\"fp16\",  # REMOVED: Community model doesn't have fp16 variants\n",
        "        low_cpu_mem_usage=True,     # Minimize CPU memory during loading\n",
        "    )\n",
        "\n",
        "    print(\"\\nüîß Applying A100 optimizations...\")\n",
        "\n",
        "    # Essential memory optimizations for 40GB constraint\n",
        "    pipe.enable_sequential_cpu_offload()  # Most aggressive memory optimization\n",
        "    pipe.vae.enable_tiling()              # Reduce VAE memory usage\n",
        "    pipe.vae.enable_slicing()             # Further VAE optimization\n",
        "\n",
        "    # Enable memory-efficient attention if available\n",
        "    try:\n",
        "        pipe.enable_xformers_memory_efficient_attention()\n",
        "        print(\"   ‚úÖ xFormers memory-efficient attention enabled\")\n",
        "    except ImportError:\n",
        "        print(\"   ‚ö†Ô∏è xFormers not available - using default attention\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è xFormers setup issue: {e}\")\n",
        "\n",
        "    # Configure scheduler for memory efficiency\n",
        "    if hasattr(pipe.scheduler, 'enable_low_mem_usage'):\n",
        "        pipe.scheduler.enable_low_mem_usage = True\n",
        "\n",
        "    load_time = time.time() - start_time\n",
        "    print(f\"\\n‚úÖ HunyuanVideo loaded successfully in {load_time:.1f}s\")\n",
        "    print(\"üé¨ Ready for video generation!\")\n",
        "\n",
        "    print_memory_status(\"(After model loading)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to load HunyuanVideo: {str(e)}\")\n",
        "    print(\"\\nüîç Troubleshooting steps:\")\n",
        "    print(\"1. Ensure you have A100 GPU access\")\n",
        "    print(\"2. Check available disk space (need ~30GB)\")\n",
        "    print(\"3. Restart runtime and try again\")\n",
        "    raise"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config-header"
      },
      "source": [
        "## ‚öôÔ∏è 5. A100-Optimized Generation Settings\n",
        "\n",
        "Configure generation parameters optimized for A100 40GB memory constraints while maintaining high quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config-settings"
      },
      "outputs": [],
      "source": [
        "# A100 40GB optimized configurations\n",
        "COLAB_CONFIGS = {\n",
        "    \"high_quality\": {\n",
        "        \"height\": 720,\n",
        "        \"width\": 1280,\n",
        "        \"num_frames\": 65,           # Reduced from 129 for memory\n",
        "        \"guidance_scale\": 7.0,\n",
        "        \"num_inference_steps\": 30,  # Balanced quality/speed\n",
        "        \"description\": \"High quality 720p (may use significant memory)\"\n",
        "    },\n",
        "    \"balanced\": {\n",
        "        \"height\": 544,\n",
        "        \"width\": 960,\n",
        "        \"num_frames\": 65,\n",
        "        \"guidance_scale\": 7.0,\n",
        "        \"num_inference_steps\": 25,\n",
        "        \"description\": \"Balanced quality and memory usage (recommended)\"\n",
        "    },\n",
        "    \"fast\": {\n",
        "        \"height\": 512,\n",
        "        \"width\": 512,\n",
        "        \"num_frames\": 32,\n",
        "        \"guidance_scale\": 6.0,\n",
        "        \"num_inference_steps\": 20,\n",
        "        \"description\": \"Fast generation with lower memory usage\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def print_config_options():\n",
        "    \"\"\"Display available configuration options.\"\"\"\n",
        "    print(\"üìä Available Quality Configurations:\")\n",
        "    for name, config in COLAB_CONFIGS.items():\n",
        "        duration = config['num_frames'] / 8  # Assuming 8 FPS\n",
        "        print(f\"\\nüé• {name.upper()}:\")\n",
        "        print(f\"   Resolution: {config['width']}x{config['height']}\")\n",
        "        print(f\"   Duration: ~{duration:.1f}s ({config['num_frames']} frames)\")\n",
        "        print(f\"   Steps: {config['num_inference_steps']}\")\n",
        "        print(f\"   üí° {config['description']}\")\n",
        "\n",
        "print_config_options()\n",
        "\n",
        "# Memory usage estimates\n",
        "print(\"\\nüíæ Estimated Memory Usage:\")\n",
        "print(\"   High Quality: ~35-38GB (may require cleanup between generations)\")\n",
        "print(\"   Balanced: ~25-30GB (recommended for most use cases)\")\n",
        "print(\"   Fast: ~15-20GB (reliable for multiple generations)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "generation-header"
      },
      "source": [
        "## üé¨ 6. Interactive Video Generation\n",
        "\n",
        "Generate high-quality videos with HunyuanVideo using your custom prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generation-function"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Video, display\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def generate_video_colab(\n",
        "    prompt: str,\n",
        "    quality: str = \"balanced\",\n",
        "    seed: int = None,\n",
        "    output_dir: str = \"/content/videos\"\n",
        ") -> str:\n",
        "    \"\"\"Generate video with HunyuanVideo optimized for Colab A100.\n",
        "\n",
        "    Args:\n",
        "        prompt: Text description of the video to generate\n",
        "        quality: 'high_quality', 'balanced', or 'fast'\n",
        "        seed: Random seed for reproducible results\n",
        "        output_dir: Directory to save generated videos\n",
        "\n",
        "    Returns:\n",
        "        Path to generated video file\n",
        "    \"\"\"\n",
        "    if quality not in COLAB_CONFIGS:\n",
        "        quality = \"balanced\"\n",
        "        print(f\"‚ö†Ô∏è Invalid quality setting, using 'balanced'\")\n",
        "\n",
        "    config = COLAB_CONFIGS[quality]\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Generate filename with timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"hunyuan_{quality}_{timestamp}.mp4\"\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "\n",
        "    print(f\"üé¨ Generating video with {quality} settings...\")\n",
        "    print(f\"üìù Prompt: {prompt}\")\n",
        "    print(f\"üéØ Resolution: {config['width']}x{config['height']}\")\n",
        "    print(f\"‚è±Ô∏è Frames: {config['num_frames']} (~{config['num_frames']/8:.1f}s)\")\n",
        "\n",
        "    print_memory_status(\"(Before generation)\")\n",
        "\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Set random seed for reproducibility\n",
        "        generator = None\n",
        "        if seed is not None:\n",
        "            generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "            print(f\"üé≤ Using seed: {seed}\")\n",
        "\n",
        "        # Generate video with progress tracking\n",
        "        print(\"\\nüîÑ Generating frames...\")\n",
        "        video = pipe(\n",
        "            prompt=prompt,\n",
        "            height=config[\"height\"],\n",
        "            width=config[\"width\"],\n",
        "            num_frames=config[\"num_frames\"],\n",
        "            guidance_scale=config[\"guidance_scale\"],\n",
        "            num_inference_steps=config[\"num_inference_steps\"],\n",
        "            generator=generator,\n",
        "            output_type=\"pil\"  # PIL format for easier handling\n",
        "        ).frames[0]\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "\n",
        "        # Save video using imageio with H.264 codec\n",
        "        print(\"\\nüíæ Saving video...\")\n",
        "        import imageio\n",
        "        with imageio.get_writer(output_path, fps=8, codec='h264', quality=8) as writer:\n",
        "            for frame in video:\n",
        "                writer.append_data(frame)\n",
        "\n",
        "        # Get file size\n",
        "        file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB\n",
        "\n",
        "        print(f\"\\n‚úÖ Video generated successfully!\")\n",
        "        print(f\"   ‚è±Ô∏è Generation time: {generation_time:.1f}s\")\n",
        "        print(f\"   üíæ File size: {file_size:.1f} MB\")\n",
        "        print(f\"   üìÅ Saved to: {output_path}\")\n",
        "\n",
        "        print_memory_status(\"(After generation)\")\n",
        "\n",
        "        return output_path\n",
        "\n",
        "    except torch.cuda.OutOfMemoryError:\n",
        "        print(\"\\n‚ùå GPU out of memory!\")\n",
        "        cleanup_memory()\n",
        "        print(\"\\nüí° Try these solutions:\")\n",
        "        print(\"   1. Use 'fast' quality setting\")\n",
        "        print(\"   2. Reduce num_frames or resolution\")\n",
        "        print(\"   3. Restart runtime to clear memory\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Generation failed: {str(e)}\")\n",
        "        cleanup_memory()\n",
        "        raise\n",
        "\n",
        "print(\"üé¨ Video generation function ready!\")\n",
        "print(\"üìù Use generate_video_colab(prompt, quality) to create videos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "examples-header"
      },
      "source": [
        "## üé® 7. Example Generations\n",
        "\n",
        "Try these example prompts or create your own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "example-1"
      },
      "outputs": [],
      "source": [
        "# Example 1: Balanced quality generation\n",
        "prompt_1 = \"A majestic golden eagle soaring over snow-capped mountains at sunset, cinematic camera movement, high detail, beautiful lighting\"\n",
        "\n",
        "video_path_1 = generate_video_colab(\n",
        "    prompt=prompt_1,\n",
        "    quality=\"balanced\",\n",
        "    seed=42  # For reproducible results\n",
        ")\n",
        "\n",
        "# Display the generated video\n",
        "print(\"\\nüé• Generated Video:\")\n",
        "display(Video(video_path_1, width=600))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "example-2"
      },
      "outputs": [],
      "source": [
        "# Example 2: High quality generation (use with caution on memory)\n",
        "prompt_2 = \"A futuristic cyberpunk city at night with neon lights reflecting in rain puddles, flying cars in the distance, dramatic atmosphere\"\n",
        "\n",
        "# Check memory before high-quality generation\n",
        "mem = get_gpu_memory()\n",
        "if mem['free'] > 25:\n",
        "    print(\"üöÄ Sufficient memory detected - proceeding with high quality\")\n",
        "    video_path_2 = generate_video_colab(\n",
        "        prompt=prompt_2,\n",
        "        quality=\"high_quality\",\n",
        "        seed=123\n",
        "    )\n",
        "    display(Video(video_path_2, width=600))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Limited memory - using balanced quality instead\")\n",
        "    video_path_2 = generate_video_colab(\n",
        "        prompt=prompt_2,\n",
        "        quality=\"balanced\",\n",
        "        seed=123\n",
        "    )\n",
        "    display(Video(video_path_2, width=600))\n",
        "\n",
        "# Cleanup memory after generation\n",
        "cleanup_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "custom-generation"
      },
      "outputs": [],
      "source": [
        "# Custom generation - Enter your own prompt!\n",
        "custom_prompt = input(\"Enter your video prompt: \")\n",
        "quality_choice = input(\"Choose quality (high_quality/balanced/fast): \") or \"balanced\"\n",
        "custom_seed = input(\"Enter seed (or press enter for random): \")\n",
        "\n",
        "seed_value = None\n",
        "if custom_seed.strip():\n",
        "    try:\n",
        "        seed_value = int(custom_seed)\n",
        "    except ValueError:\n",
        "        print(\"Invalid seed, using random\")\n",
        "\n",
        "if custom_prompt.strip():\n",
        "    custom_video_path = generate_video_colab(\n",
        "        prompt=custom_prompt,\n",
        "        quality=quality_choice,\n",
        "        seed=seed_value\n",
        "    )\n",
        "    display(Video(custom_video_path, width=600))\n",
        "else:\n",
        "    print(\"No prompt entered, skipping generation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "batch-header"
      },
      "source": [
        "## üìö 8. Batch Generation\n",
        "\n",
        "Generate multiple videos with automatic memory management."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batch-generation"
      },
      "outputs": [],
      "source": [
        "def batch_generate_videos(prompts_and_configs: list, output_dir: str = \"/content/batch_videos\"):\n",
        "    \"\"\"Generate multiple videos with automatic memory cleanup.\n",
        "\n",
        "    Args:\n",
        "        prompts_and_configs: List of (prompt, quality, seed) tuples\n",
        "        output_dir: Directory for batch outputs\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    results = []\n",
        "\n",
        "    print(f\"üé¨ Starting batch generation of {len(prompts_and_configs)} videos...\")\n",
        "\n",
        "    for i, config in enumerate(prompts_and_configs, 1):\n",
        "        prompt = config[0]\n",
        "        quality = config[1] if len(config) > 1 else \"balanced\"\n",
        "        seed = config[2] if len(config) > 2 else None\n",
        "\n",
        "        print(f\"\\nüìπ Generation {i}/{len(prompts_and_configs)}:\")\n",
        "        print(f\"   Prompt: {prompt[:60]}...\" if len(prompt) > 60 else f\"   Prompt: {prompt}\")\n",
        "\n",
        "        try:\n",
        "            video_path = generate_video_colab(\n",
        "                prompt=prompt,\n",
        "                quality=quality,\n",
        "                seed=seed,\n",
        "                output_dir=output_dir\n",
        "            )\n",
        "            results.append((prompt, video_path, \"success\"))\n",
        "\n",
        "            # Cleanup memory between generations\n",
        "            if i < len(prompts_and_configs):  # Don't cleanup after last generation\n",
        "                print(\"üßπ Cleaning up memory for next generation...\")\n",
        "                cleanup_memory()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed: {str(e)}\")\n",
        "            results.append((prompt, None, f\"error: {str(e)}\"))\n",
        "            cleanup_memory()  # Always cleanup on error\n",
        "\n",
        "    print(f\"\\n‚úÖ Batch generation completed!\")\n",
        "    print(f\"üìä Results: {sum(1 for r in results if r[2] == 'success')}/{len(results)} successful\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example batch generation\n",
        "sample_batch = [\n",
        "    (\"A cat playing with a ball of yarn in slow motion\", \"fast\", 111),\n",
        "    (\"Ocean waves crashing on a rocky shore at dawn\", \"balanced\", 222),\n",
        "    (\"A hummingbird feeding from colorful flowers\", \"balanced\", 333)\n",
        "]\n",
        "\n",
        "print(\"üé¨ Example batch ready to run!\")\n",
        "print(\"üìù Uncomment the line below to start batch generation:\")\n",
        "print(\"# batch_results = batch_generate_videos(sample_batch)\")\n",
        "\n",
        "# Uncomment to run:\n",
        "# batch_results = batch_generate_videos(sample_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "export-header"
      },
      "source": [
        "## üíæ 9. Export & Download\n",
        "\n",
        "Export your generated videos to Google Drive or download them directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount-drive"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive for permanent storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def copy_to_drive(video_path: str, drive_folder: str = \"HunyuanVideo_Outputs\"):\n",
        "    \"\"\"Copy generated video to Google Drive.\"\"\"\n",
        "    import shutil\n",
        "\n",
        "    drive_path = f\"/content/drive/MyDrive/{drive_folder}\"\n",
        "    os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "    filename = os.path.basename(video_path)\n",
        "    drive_file = os.path.join(drive_path, filename)\n",
        "\n",
        "    shutil.copy2(video_path, drive_file)\n",
        "    print(f\"‚úÖ Video copied to Google Drive: {drive_file}\")\n",
        "    return drive_file\n",
        "\n",
        "def download_video(video_path: str):\n",
        "    \"\"\"Download video to local machine.\"\"\"\n",
        "    from google.colab import files\n",
        "    if os.path.exists(video_path):\n",
        "        files.download(video_path)\n",
        "        print(f\"‚¨áÔ∏è Download started for: {os.path.basename(video_path)}\")\n",
        "    else:\n",
        "        print(f\"‚ùå File not found: {video_path}\")\n",
        "\n",
        "print(\"üíæ Google Drive mounted successfully!\")\n",
        "print(\"üìÅ Use copy_to_drive(video_path) to save to Drive\")\n",
        "print(\"‚¨áÔ∏è Use download_video(video_path) to download directly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "list-generated"
      },
      "outputs": [],
      "source": [
        "# List all generated videos\n",
        "import glob\n",
        "\n",
        "video_dirs = [\"/content/videos\", \"/content/batch_videos\"]\n",
        "all_videos = []\n",
        "\n",
        "for video_dir in video_dirs:\n",
        "    if os.path.exists(video_dir):\n",
        "        videos = glob.glob(os.path.join(video_dir, \"*.mp4\"))\n",
        "        all_videos.extend(videos)\n",
        "\n",
        "if all_videos:\n",
        "    print(f\"üé¨ Found {len(all_videos)} generated videos:\")\n",
        "    for i, video_path in enumerate(all_videos, 1):\n",
        "        file_size = os.path.getsize(video_path) / (1024 * 1024)\n",
        "        print(f\"   {i}. {os.path.basename(video_path)} ({file_size:.1f} MB)\")\n",
        "\n",
        "    print(\"\\nüíæ Export options:\")\n",
        "    print(\"   # Copy all videos to Google Drive\")\n",
        "    print(\"   for video in all_videos: copy_to_drive(video)\")\n",
        "    print(\"\")\n",
        "    print(\"   # Download specific video (replace index)\")\n",
        "    print(\"   download_video(all_videos[0])  # Downloads first video\")\n",
        "else:\n",
        "    print(\"üì≠ No videos found. Generate some videos first!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "export-all"
      },
      "outputs": [],
      "source": [
        "# Quick export all videos to Drive\n",
        "if all_videos:\n",
        "    export_choice = input(\"Export all videos to Google Drive? (y/n): \")\n",
        "    if export_choice.lower() == 'y':\n",
        "        print(\"üì§ Exporting all videos to Google Drive...\")\n",
        "        for video_path in all_videos:\n",
        "            try:\n",
        "                copy_to_drive(video_path)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to copy {video_path}: {e}\")\n",
        "        print(\"‚úÖ Export completed!\")\n",
        "    else:\n",
        "        print(\"üìã Export skipped. Use copy_to_drive(video_path) for individual files.\")\n",
        "else:\n",
        "    print(\"üì≠ No videos to export.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troubleshooting-header"
      },
      "source": [
        "## üîß 10. Troubleshooting & Optimization\n",
        "\n",
        "Common issues and solutions for HunyuanVideo on Colab A100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diagnostics"
      },
      "outputs": [],
      "source": [
        "def run_diagnostics():\n",
        "    \"\"\"Run comprehensive system diagnostics.\"\"\"\n",
        "    print(\"üîç Running HunyuanVideo Colab Diagnostics...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # GPU Information\n",
        "    print(\"\\nüñ•Ô∏è GPU Information:\")\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_props = torch.cuda.get_device_properties(0)\n",
        "        print(f\"   GPU: {gpu_props.name}\")\n",
        "        print(f\"   Total Memory: {gpu_props.total_memory / 1024**3:.1f} GB\")\n",
        "        print(f\"   CUDA Capability: {gpu_props.major}.{gpu_props.minor}\")\n",
        "\n",
        "        # Check if A100\n",
        "        if \"A100\" in gpu_props.name:\n",
        "            print(\"   ‚úÖ A100 GPU detected - optimal for HunyuanVideo\")\n",
        "        else:\n",
        "            print(\"   ‚ö†Ô∏è Non-A100 GPU - may need optimization\")\n",
        "    else:\n",
        "        print(\"   ‚ùå No GPU available\")\n",
        "\n",
        "    # Memory Status\n",
        "    print_memory_status(\"\\nüß† Current Memory\")\n",
        "\n",
        "    # Disk Space\n",
        "    print(\"\\nüíæ Disk Space:\")\n",
        "    import shutil\n",
        "    total, used, free = shutil.disk_usage(\"/content\")\n",
        "    print(f\"   Total: {total / 1024**3:.1f} GB\")\n",
        "    print(f\"   Used: {used / 1024**3:.1f} GB\")\n",
        "    print(f\"   Free: {free / 1024**3:.1f} GB\")\n",
        "\n",
        "    if free / 1024**3 < 20:\n",
        "        print(\"   ‚ö†Ô∏è Low disk space - may affect model loading\")\n",
        "\n",
        "    # Library Versions\n",
        "    print(\"\\nüìö Library Versions:\")\n",
        "    try:\n",
        "        import diffusers, transformers, torch\n",
        "        print(f\"   PyTorch: {torch.__version__}\")\n",
        "        print(f\"   Diffusers: {diffusers.__version__}\")\n",
        "        print(f\"   Transformers: {transformers.__version__}\")\n",
        "\n",
        "        # Check versions\n",
        "        if diffusers.__version__ >= \"0.33.1\":\n",
        "            print(\"   ‚úÖ Diffusers version supports HunyuanVideo\")\n",
        "        else:\n",
        "            print(\"   ‚ö†Ô∏è Update diffusers: pip install diffusers>=0.33.1\")\n",
        "    except ImportError as e:\n",
        "        print(f\"   ‚ùå Import error: {e}\")\n",
        "\n",
        "    # Model Status\n",
        "    print(\"\\nü§ñ Model Status:\")\n",
        "    try:\n",
        "        # Check if pipe is loaded\n",
        "        if 'pipe' in globals():\n",
        "            print(\"   ‚úÖ HunyuanVideo pipeline loaded\")\n",
        "            print(f\"   Device: {next(pipe.parameters()).device}\")\n",
        "            print(f\"   Dtype: {next(pipe.parameters()).dtype}\")\n",
        "        else:\n",
        "            print(\"   ‚ùå HunyuanVideo pipeline not loaded\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Error checking model: {e}\")\n",
        "\n",
        "    print(\"\\nüîß Optimization Status:\")\n",
        "    print(f\"   TF32 enabled: {torch.backends.cuda.matmul.allow_tf32}\")\n",
        "    print(f\"   cuDNN benchmark: {torch.backends.cudnn.benchmark}\")\n",
        "    print(f\"   Memory fraction: {torch.cuda.get_memory_fraction(0) if torch.cuda.is_available() else 'N/A'}\")\n",
        "\n",
        "def memory_optimization_tips():\n",
        "    \"\"\"Show memory optimization tips.\"\"\"\n",
        "    print(\"üí° Memory Optimization Tips:\")\n",
        "    print(\"=\" * 30)\n",
        "    print(\"\\nüîß If you get Out of Memory errors:\")\n",
        "    print(\"   1. Use 'fast' quality setting\")\n",
        "    print(\"   2. Reduce num_frames (try 32 instead of 65)\")\n",
        "    print(\"   3. Lower resolution (512x512 instead of 720p)\")\n",
        "    print(\"   4. Restart runtime to clear memory\")\n",
        "    print(\"   5. Run cleanup_memory() between generations\")\n",
        "\n",
        "    print(\"\\n‚ö° For better performance:\")\n",
        "    print(\"   1. Use sequential_cpu_offload (already enabled)\")\n",
        "    print(\"   2. Enable VAE tiling (already enabled)\")\n",
        "    print(\"   3. Use FP16 precision (already enabled)\")\n",
        "    print(\"   4. Generate videos one at a time\")\n",
        "    print(\"   5. Close browser tabs to free system RAM\")\n",
        "\n",
        "# Run diagnostics\n",
        "run_diagnostics()\n",
        "memory_optimization_tips()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emergency-cleanup"
      },
      "outputs": [],
      "source": [
        "# Emergency memory cleanup\n",
        "def emergency_cleanup():\n",
        "    \"\"\"Aggressive memory cleanup for emergency situations.\"\"\"\n",
        "    print(\"üö® Running emergency memory cleanup...\")\n",
        "\n",
        "    # Clear Python variables\n",
        "    if 'pipe' in globals():\n",
        "        print(\"   Clearing pipeline...\")\n",
        "        del pipe\n",
        "\n",
        "    # Garbage collection\n",
        "    import gc\n",
        "    gc.collect()\n",
        "\n",
        "    # CUDA cleanup\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        print(\"   CUDA cache cleared\")\n",
        "\n",
        "    # Check memory after cleanup\n",
        "    print_memory_status(\"(After cleanup)\")\n",
        "\n",
        "    print(\"‚úÖ Emergency cleanup completed\")\n",
        "    print(\"üí° You may need to reload the model with the loading cell above\")\n",
        "\n",
        "print(\"üö® Emergency cleanup function ready\")\n",
        "print(\"üìù Run emergency_cleanup() if you encounter memory issues\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion-header"
      },
      "source": [
        "## üéâ Conclusion\n",
        "\n",
        "Congratulations! You've successfully set up and used HunyuanVideo on Google Colab A100.\n",
        "\n",
        "### üéØ What You've Accomplished:\n",
        "- ‚úÖ Loaded a 13B parameter video generation model on Colab\n",
        "- ‚úÖ Optimized for A100 40GB memory constraints\n",
        "- ‚úÖ Generated high-quality videos up to 15 seconds\n",
        "- ‚úÖ Learned memory management for large AI models\n",
        "- ‚úÖ Set up batch generation and export workflows\n",
        "\n",
        "### üöÄ Next Steps:\n",
        "1. **Experiment** with different prompts and quality settings\n",
        "2. **Explore** the full videogenbook library for more models\n",
        "3. **Read** the complete guide: *Hands-On Video Generation with AI*\n",
        "4. **Join** the community: [GitHub Repository](https://github.com/jenochs/video-generation-book)\n",
        "\n",
        "### üîó Resources:\n",
        "- **Documentation**: [videogenbook docs](https://github.com/jenochs/video-generation-book)\n",
        "- **HunyuanVideo**: [Model Card](https://huggingface.co/tencent/HunyuanVideo)\n",
        "- **Colab Pro+**: [Upgrade for A100 access](https://colab.research.google.com/signup)\n",
        "\n",
        "### üí° Tips for Best Results:\n",
        "- Use detailed, descriptive prompts\n",
        "- Include camera movement descriptions\n",
        "- Specify lighting and atmosphere\n",
        "- Experiment with different seeds for variety\n",
        "- Monitor memory usage for stable generation\n",
        "\n",
        "**Happy video generating! üé¨‚ú®**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}