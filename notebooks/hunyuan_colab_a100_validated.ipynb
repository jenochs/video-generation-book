{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143e89e8",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# HunyuanVideo on Google Colab A100\\n\\n**Generate high-quality videos using Tencent's official HunyuanVideo model on Google Colab A100 GPU**\\n\\n🚀 **What you'll learn:**\\n- Run the official 13B parameter HunyuanVideo model on Colab A100 (40GB)\\n- Use exact package versions for maximum compatibility\\n- Optimize memory usage for large-scale video generation\\n- Generate videos up to 15 seconds with advanced prompting\\n- Export and download high-quality video results\\n\\n⚡ **Requirements:**\\n- Google Colab Pro+ with A100 GPU access\\n- ~20-30 minutes for complete setup\\n- Google Drive for video storage (optional)\\n\\n📚 **Model Info:** Official tencent/HunyuanVideo (integrated into Diffusers Dec 17, 2024)\\n📖 **From the Book:** *Hands-On Video Generation with AI* - Chapter 3: Advanced Model Implementation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4ad2e",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 🔧 1. Environment Setup & GPU Verification\n",
    "\n",
    "First, let's verify we have an A100 GPU and configure the environment for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd8660f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpu-check",
    "outputId": "5039383e-aeee-4a87-88df-7a1d076a9b8c"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability and specifications\\n!nvidia-smi\\n\\n# Verify we have A100 access\\nimport subprocess\\nresult = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'],\\n                       capture_output=True, text=True)\\nprint(\\\"GPU Information:\\\")\\ngpu_info = result.stdout.strip().split(', ')\\nif len(gpu_info) >= 2:\\n    gpu_name, gpu_memory = gpu_info[0], int(gpu_info[1])\\n    print(f\\\"   GPU: {gpu_name}\\\")\\n    print(f\\\"   Memory: {gpu_memory:,} MB ({gpu_memory/1024:.1f} GB)\\\")\\n\\n    if \\\"A100\\\" in gpu_name and gpu_memory >= 40000:\\n        print(\\\"   ✅ Perfect! A100 40GB detected - optimal for HunyuanVideo\\\")\\n    elif \\\"A100\\\" in gpu_name:\\n        print(\\\"   ⚠️ A100 detected but check memory - may need optimization\\\")\\n    else:\\n        print(\\\"   ❌ Warning: A100 GPU recommended for best performance\\\")\\n        print(\\\"   💡 Consider upgrading to Colab Pro+ for A100 access\\\")\\nelse:\\n    print(\\\"   ❌ Unable to detect GPU information\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e35ae7",
   "metadata": {
    "id": "install-header"
   },
   "source": [
    "## 📦 2. Install Dependencies\\n\\nInstall the exact package versions required by HunyuanVideo (official requirements from Dec 2024).\\n\\n**Important**: These specific versions are tested and verified to work with HunyuanVideo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb28c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "install-pytorch",
    "outputId": "e01ed6b9-f9fe-4778-e5a0-8c8c14fed5f5"
   },
   "outputs": [],
   "source": [
    "# Install PyTorch with CUDA 12.1 support (optimized for A100)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ccab8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "install-diffusers",
    "outputId": "dc794863-3565-425c-eb18-1ce0532036bc"
   },
   "outputs": [],
   "source": [
    "# Install HunyuanVideo dependencies (exact official versions)\\n!pip install diffusers==0.31.0  # Official HunyuanVideo requirement\\n!pip install transformers==4.46.3  # Official HunyuanVideo requirement  \\n!pip install accelerate==1.1.1  # Official HunyuanVideo requirement\\n!pip install safetensors==0.4.5 tokenizers==0.20.3  # Official supporting versions\\n!pip install xformers  # Latest version for A100 optimization\\n!pip install imageio-ffmpeg einops  # For video processing and tensor operations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb6735c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "install-videogenbook",
    "outputId": "dfd75522-216f-4fb3-c30f-d42fcf88feef"
   },
   "outputs": [],
   "source": [
    "# Verify installation and imports\\nimport torch\\nimport diffusers\\nimport transformers\\nimport accelerate\\n\\nprint(\\\"✅ Package Installation Verified:\\\")\\nprint(f\\\"   PyTorch: {torch.__version__}\\\")\\nprint(f\\\"   Diffusers: {diffusers.__version__}\\\")\\nprint(f\\\"   Transformers: {transformers.__version__}\\\")\\nprint(f\\\"   Accelerate: {accelerate.__version__}\\\")\\nprint(f\\\"   CUDA available: {torch.cuda.is_available()}\\\")\\n\\n# Check if versions match HunyuanVideo requirements\\nif diffusers.__version__ >= \\\"0.31.0\\\":\\n    print(\\\"   ✅ Diffusers version supports HunyuanVideo\\\")\\nelse:\\n    print(\\\"   ⚠️ Diffusers version may not support HunyuanVideo\\\")\\n\\nif transformers.__version__ >= \\\"4.46.3\\\":\\n    print(\\\"   ✅ Transformers version compatible\\\")\\nelse:\\n    print(\\\"   ⚠️ Transformers version may need update\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b502676",
   "metadata": {
    "id": "env-config"
   },
   "outputs": [],
   "source": [
    "# Configure environment for maximum memory efficiency\\nimport os\\nimport torch\\n\\n# Essential memory optimizations for A100 40GB\\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\\nos.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # Async for better performance\\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'  # Avoid warnings\\n\\n# Enable optimized math operations\\ntorch.backends.cuda.matmul.allow_tf32 = True\\ntorch.backends.cudnn.allow_tf32 = True\\ntorch.backends.cudnn.benchmark = True\\n\\nprint(\\\"🔧 Environment configured for A100 optimization\\\")\\nprint(f\\\"   PyTorch version: {torch.__version__}\\\")\\nprint(f\\\"   CUDA available: {torch.cuda.is_available()}\\\")\\nif torch.cuda.is_available():\\n    print(f\\\"   CUDA version: {torch.version.cuda}\\\")\\n    print(f\\\"   GPU count: {torch.cuda.device_count()}\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa5235",
   "metadata": {
    "id": "memory-header"
   },
   "source": [
    "## 🧠 3. Memory Monitoring & Optimization\n",
    "\n",
    "Set up memory monitoring and configure HunyuanVideo for A100 40GB constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09080512",
   "metadata": {
    "id": "memory-utils"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from typing import Dict, Any\n",
    "\n",
    "def get_gpu_memory() -> Dict[str, float]:\n",
    "    \"\"\"Get current GPU memory usage in GB.\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return {\"total\": 0, \"used\": 0, \"free\": 0}\n",
    "\n",
    "    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "    cached = torch.cuda.memory_reserved() / 1024**3\n",
    "    free = total - cached\n",
    "\n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"allocated\": allocated,\n",
    "        \"cached\": cached,\n",
    "        \"free\": free\n",
    "    }\n",
    "\n",
    "def print_memory_status(stage: str = \"\"):\n",
    "    \"\"\"Print current memory status.\"\"\"\n",
    "    mem = get_gpu_memory()\n",
    "    print(f\"🧠 GPU Memory {stage}:\")\n",
    "    print(f\"   Total: {mem['total']:.1f} GB\")\n",
    "    print(f\"   Allocated: {mem['allocated']:.1f} GB\")\n",
    "    print(f\"   Cached: {mem['cached']:.1f} GB\")\n",
    "    print(f\"   Free: {mem['free']:.1f} GB\")\n",
    "\n",
    "    # Memory warnings\n",
    "    if mem['free'] < 10:\n",
    "        print(\"   ⚠️ Low memory - consider reducing resolution/frames\")\n",
    "    elif mem['free'] < 20:\n",
    "        print(\"   ✅ Sufficient memory for standard generation\")\n",
    "    else:\n",
    "        print(\"   🚀 Excellent memory - can use higher quality settings\")\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"Cleanup GPU memory.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "# Initial memory check\n",
    "print_memory_status(\"(Initial)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbc8315",
   "metadata": {
    "id": "model-header"
   },
   "source": [
    "## 🤖 4. Load Official HunyuanVideo Model\\n\\nLoad the official Tencent HunyuanVideo model with A100-optimized settings for 40GB memory constraint.\\n\\n**Note**: Using official `tencent/HunyuanVideo` model path (integrated into Diffusers Dec 17, 2024).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a411e44",
   "metadata": {
    "id": "load-model"
   },
   "outputs": [],
   "source": [
    "# Load HunyuanVideo model with A100 optimizations\\nfrom diffusers import HunyuanVideoPipeline\\nimport torch\\nimport time\\n\\nprint(\\\"🔄 Loading HunyuanVideo model (this may take 5-10 minutes)...\\\")\\nprint(\\\"📥 Downloading ~26GB of model weights...\\\")\\n\\nstart_time = time.time()\\n\\ntry:\\n    # Load official HunyuanVideo model (integrated Dec 17, 2024)\\n    pipe = HunyuanVideoPipeline.from_pretrained(\\n        \\\"tencent/HunyuanVideo\\\",  # Official model path (not community fork)\\n        torch_dtype=torch.bfloat16,  # Official recommendation: Transformer in bfloat16\\n        use_safetensors=True,\\n        low_cpu_mem_usage=True,     # Minimize CPU memory during loading\\n    )\\n\\n    print(\\\"Applying A100 optimizations...\\\")\\n\\n    # Essential memory optimizations for 40GB constraint\\n    pipe.enable_sequential_cpu_offload()  # Most aggressive memory optimization\\n    pipe.vae.enable_tiling()              # Reduce VAE memory usage\\n    pipe.vae.enable_slicing()             # Further VAE optimization\\n\\n    # Set optimal dtypes as per official docs\\n    # VAE and text encoders should be in float16, Transformer in bfloat16\\n    pipe.vae = pipe.vae.to(torch.float16)\\n    if hasattr(pipe, 'text_encoder'):\\n        pipe.text_encoder = pipe.text_encoder.to(torch.float16)\\n    if hasattr(pipe, 'text_encoder_2'):\\n        pipe.text_encoder_2 = pipe.text_encoder_2.to(torch.float16)\\n\\n    # Enable memory-efficient attention if available\\n    try:\\n        pipe.enable_xformers_memory_efficient_attention()\\n        print(\\\"   ✅ xFormers memory-efficient attention enabled\\\")\\n    except ImportError:\\n        print(\\\"   ⚠️ xFormers not available - using default attention\\\")\\n    except Exception as e:\\n        print(f\\\"   ⚠️ xFormers setup issue: {e}\\\")\\n\\n    load_time = time.time() - start_time\\n    print(f\\\"✅ HunyuanVideo loaded successfully in {load_time:.1f}s\\\")\\n    print(\\\"🎬 Ready for video generation!\\\")\\n\\n    print_memory_status(\\\"(After model loading)\\\")\\n\\nexcept Exception as e:\\n    print(f\\\"❌ Failed to load HunyuanVideo: {str(e)}\\\")\\n    print(\\\"Troubleshooting steps:\\\")\\n    print(\\\"1. Ensure you have A100 GPU access\\\")\\n    print(\\\"2. Check available disk space (need ~30GB)\\\")\\n    print(\\\"3. Restart runtime and try again\\\")\\n    print(\\\"4. Try using hunyuanvideo-community/HunyuanVideo if official fails\\\")\\n    raise\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93981bff",
   "metadata": {
    "id": "config-header"
   },
   "source": [
    "## ⚙️ 5. A100-Optimized Generation Settings\n",
    "\n",
    "Configure generation parameters optimized for A100 40GB memory constraints while maintaining high quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e71e2",
   "metadata": {
    "id": "config-settings"
   },
   "outputs": [],
   "source": [
    "# A100 40GB optimized configurations\\nCOLAB_CONFIGS = {\\n    \\\"high_quality\\\": {\\n        \\\"height\\\": 720,\\n        \\\"width\\\": 1280,\\n        \\\"num_frames\\\": 65,           # Reduced from 129 for memory\\n        \\\"guidance_scale\\\": 7.0,\\n        \\\"num_inference_steps\\\": 30,  # Balanced quality/speed\\n        \\\"description\\\": \\\"High quality 720p (may use significant memory)\\\"\\n    },\\n    \\\"balanced\\\": {\\n        \\\"height\\\": 544,\\n        \\\"width\\\": 960,\\n        \\\"num_frames\\\": 65,\\n        \\\"guidance_scale\\\": 7.0,\\n        \\\"num_inference_steps\\\": 25,\\n        \\\"description\\\": \\\"Balanced quality and memory usage (recommended)\\\"\\n    },\\n    \\\"fast\\\": {\\n        \\\"height\\\": 512,\\n        \\\"width\\\": 512,\\n        \\\"num_frames\\\": 32,\\n        \\\"guidance_scale\\\": 6.0,\\n        \\\"num_inference_steps\\\": 20,\\n        \\\"description\\\": \\\"Fast generation with lower memory usage\\\"\\n    }\\n}\\n\\ndef print_config_options():\\n    \\\"\\\"\\\"Display available configuration options.\\\"\\\"\\\"\\n    print(\\\"📊 Available Quality Configurations:\\\")\\n    for name, config in COLAB_CONFIGS.items():\\n        duration = config['num_frames'] / 8  # Assuming 8 FPS\\n        print(f\\\"\\\")\\n        print(f\\\"🎥 {name.upper()}:\\\")\\n        print(f\\\"   Resolution: {config['width']}x{config['height']}\\\")\\n        print(f\\\"   Duration: ~{duration:.1f}s ({config['num_frames']} frames)\\\")\\n        print(f\\\"   Steps: {config['num_inference_steps']}\\\")\\n        print(f\\\"   💡 {config['description']}\\\")\\n\\nprint_config_options()\\n\\n# Memory usage estimates\\nprint(\\\"\\\")\\nprint(\\\"💾 Estimated Memory Usage:\\\")\\nprint(\\\"   High Quality: ~35-38GB (may require cleanup between generations)\\\")\\nprint(\\\"   Balanced: ~25-30GB (recommended for most use cases)\\\")\\nprint(\\\"   Fast: ~15-20GB (reliable for multiple generations)\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2608de",
   "metadata": {
    "id": "generation-header"
   },
   "source": [
    "## 🎬 6. Interactive Video Generation\n",
    "\n",
    "Generate high-quality videos with HunyuanVideo using your custom prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500fdde",
   "metadata": {
    "id": "generation-function"
   },
   "outputs": [],
   "source": [
    "# Enhanced video generation function with correct output handling\\nfrom IPython.display import Video, display\\nimport os\\nfrom datetime import datetime\\nimport numpy as np\\n\\ndef generate_video_colab(\\n    prompt: str,\\n    quality: str = \\\"balanced\\\",\\n    seed: int = None,\\n    output_dir: str = \\\"/content/videos\\\"\\n) -> str:\\n    \\\"\\\"\\\"Generate video with HunyuanVideo optimized for Colab A100.\\n\\n    Args:\\n        prompt: Text description of the video to generate\\n        quality: 'high_quality', 'balanced', or 'fast'\\n        seed: Random seed for reproducible results\\n        output_dir: Directory to save generated videos\\n\\n    Returns:\\n        Path to generated video file\\n    \\\"\\\"\\\"\\n    if quality not in COLAB_CONFIGS:\\n        quality = \\\"balanced\\\"\\n        print(f\\\"⚠️ Invalid quality setting, using 'balanced'\\\")\\n\\n    config = COLAB_CONFIGS[quality]\\n\\n    # Create output directory\\n    os.makedirs(output_dir, exist_ok=True)\\n\\n    # Generate filename with timestamp\\n    timestamp = datetime.now().strftime(\\\"%Y%m%d_%H%M%S\\\")\\n    filename = f\\\"hunyuan_{quality}_{timestamp}.mp4\\\"\\n    output_path = os.path.join(output_dir, filename)\\n\\n    print(f\\\"🎬 Generating video with {quality} settings...\\\")\\n    print(f\\\"📝 Prompt: {prompt}\\\")\\n    print(f\\\"🎯 Resolution: {config['width']}x{config['height']}\\\")\\n    print(f\\\"⏱️ Frames: {config['num_frames']} (~{config['num_frames']/8:.1f}s)\\\")\\n\\n    print_memory_status(\\\"(Before generation)\\\")\\n\\n    try:\\n        start_time = time.time()\\n\\n        # Set random seed for reproducibility\\n        generator = None\\n        if seed is not None:\\n            generator = torch.Generator(device=\\\"cuda\\\").manual_seed(seed)\\n            print(f\\\"🎲 Using seed: {seed}\\\")\\n\\n        # Generate video with correct output format\\n        print(\\\"Generating frames...\\\")\\n        result = pipe(\\n            prompt=prompt,\\n            height=config[\\\"height\\\"],\\n            width=config[\\\"width\\\"],\\n            num_frames=config[\\\"num_frames\\\"],\\n            guidance_scale=config[\\\"guidance_scale\\\"],\\n            num_inference_steps=config[\\\"num_inference_steps\\\"],\\n            generator=generator,\\n            output_type=\\\"pil\\\",  # Explicit output type for PIL Images\\n            return_dict=True    # Return HunyuanVideoPipelineOutput object\\n        )\\n\\n        # Extract frames - correct format is result.frames[0]\\n        video_frames = result.frames[0]\\n        generation_time = time.time() - start_time\\n\\n        # Save video with proper PIL Image handling\\n        print(\\\"Saving video...\\\")\\n        import imageio\\n        \\n        # Convert PIL Images to numpy arrays for imageio\\n        frames_array = []\\n        for frame in video_frames:\\n            if hasattr(frame, 'convert'):  # PIL Image\\n                frame_array = np.array(frame.convert('RGB'))\\n            else:  # Already numpy array\\n                frame_array = frame\\n            frames_array.append(frame_array)\\n\\n        # Save with H.264 codec for compatibility\\n        with imageio.get_writer(output_path, fps=8, codec='h264', quality=8) as writer:\\n            for frame_array in frames_array:\\n                writer.append_data(frame_array)\\n\\n        # Get file size\\n        file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB\\n\\n        print(f\\\"✅ Video generated successfully!\\\")\\n        print(f\\\"   ⏱️ Generation time: {generation_time:.1f}s\\\")\\n        print(f\\\"   🎬 Frames generated: {len(video_frames)}\\\")\\n        print(f\\\"   💾 File size: {file_size:.1f} MB\\\")\\n        print(f\\\"   📁 Saved to: {output_path}\\\")\\n\\n        print_memory_status(\\\"(After generation)\\\")\\n\\n        return output_path\\n\\n    except torch.cuda.OutOfMemoryError:\\n        print(\\\"❌ GPU out of memory!\\\")\\n        cleanup_memory()\\n        print(\\\"💡 Try these solutions:\\\")\\n        print(\\\"   1. Use 'fast' quality setting\\\")\\n        print(\\\"   2. Reduce num_frames or resolution\\\")\\n        print(\\\"   3. Restart runtime to clear memory\\\")\\n        raise\\n    except Exception as e:\\n        print(f\\\"❌ Generation failed: {str(e)}\\\")\\n        cleanup_memory()\\n        raise\\n\\nprint(\\\"🎬 Enhanced video generation function ready!\\\")\\nprint(\\\"📝 Use generate_video_colab(prompt, quality) to create videos\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd11c3c",
   "metadata": {
    "id": "examples-header"
   },
   "source": [
    "## 🎨 7. Example Generations\n",
    "\n",
    "Try these example prompts or create your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffcced",
   "metadata": {
    "id": "example-1"
   },
   "outputs": [],
   "source": [
    "# Example 1: Balanced quality generation\\nprompt_1 = \\\"A majestic golden eagle soaring over snow-capped mountains at sunset, cinematic camera movement, high detail, beautiful lighting\\\"\\n\\nvideo_path_1 = generate_video_colab(\\n    prompt=prompt_1,\\n    quality=\\\"balanced\\\",\\n    seed=42  # For reproducible results\\n)\\n\\n# Display the generated video\\nprint(\\\"🎥 Generated Video:\\\")\\ndisplay(Video(video_path_1, width=600))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e2b7c",
   "metadata": {
    "id": "example-2"
   },
   "outputs": [],
   "source": [
    "# Example 2: High quality generation (use with caution on memory)\n",
    "prompt_2 = \"A futuristic cyberpunk city at night with neon lights reflecting in rain puddles, flying cars in the distance, dramatic atmosphere\"\n",
    "\n",
    "# Check memory before high-quality generation\n",
    "mem = get_gpu_memory()\n",
    "if mem['free'] > 25:\n",
    "    print(\"🚀 Sufficient memory detected - proceeding with high quality\")\n",
    "    video_path_2 = generate_video_colab(\n",
    "        prompt=prompt_2,\n",
    "        quality=\"high_quality\",\n",
    "        seed=123\n",
    "    )\n",
    "    display(Video(video_path_2, width=600))\n",
    "else:\n",
    "    print(\"⚠️ Limited memory - using balanced quality instead\")\n",
    "    video_path_2 = generate_video_colab(\n",
    "        prompt=prompt_2,\n",
    "        quality=\"balanced\",\n",
    "        seed=123\n",
    "    )\n",
    "    display(Video(video_path_2, width=600))\n",
    "\n",
    "# Cleanup memory after generation\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2358971e",
   "metadata": {
    "id": "custom-generation"
   },
   "outputs": [],
   "source": [
    "# Custom generation - Enter your own prompt!\n",
    "custom_prompt = input(\"Enter your video prompt: \")\n",
    "quality_choice = input(\"Choose quality (high_quality/balanced/fast): \") or \"balanced\"\n",
    "custom_seed = input(\"Enter seed (or press enter for random): \")\n",
    "\n",
    "seed_value = None\n",
    "if custom_seed.strip():\n",
    "    try:\n",
    "        seed_value = int(custom_seed)\n",
    "    except ValueError:\n",
    "        print(\"Invalid seed, using random\")\n",
    "\n",
    "if custom_prompt.strip():\n",
    "    custom_video_path = generate_video_colab(\n",
    "        prompt=custom_prompt,\n",
    "        quality=quality_choice,\n",
    "        seed=seed_value\n",
    "    )\n",
    "    display(Video(custom_video_path, width=600))\n",
    "else:\n",
    "    print(\"No prompt entered, skipping generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e50d41",
   "metadata": {
    "id": "batch-header"
   },
   "source": [
    "## 📚 8. Batch Generation\n",
    "\n",
    "Generate multiple videos with automatic memory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb55feaf",
   "metadata": {
    "id": "batch-generation"
   },
   "outputs": [],
   "source": [
    "def batch_generate_videos(prompts_and_configs: list, output_dir: str = \"/content/batch_videos\"):\n",
    "    \"\"\"Generate multiple videos with automatic memory cleanup.\n",
    "\n",
    "    Args:\n",
    "        prompts_and_configs: List of (prompt, quality, seed) tuples\n",
    "        output_dir: Directory for batch outputs\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    print(f\"🎬 Starting batch generation of {len(prompts_and_configs)} videos...\")\n",
    "\n",
    "    for i, config in enumerate(prompts_and_configs, 1):\n",
    "        prompt = config[0]\n",
    "        quality = config[1] if len(config) > 1 else \"balanced\"\n",
    "        seed = config[2] if len(config) > 2 else None\n",
    "\n",
    "        print(f\"\\n📹 Generation {i}/{len(prompts_and_configs)}:\")\n",
    "        print(f\"   Prompt: {prompt[:60]}...\" if len(prompt) > 60 else f\"   Prompt: {prompt}\")\n",
    "\n",
    "        try:\n",
    "            video_path = generate_video_colab(\n",
    "                prompt=prompt,\n",
    "                quality=quality,\n",
    "                seed=seed,\n",
    "                output_dir=output_dir\n",
    "            )\n",
    "            results.append((prompt, video_path, \"success\"))\n",
    "\n",
    "            # Cleanup memory between generations\n",
    "            if i < len(prompts_and_configs):  # Don't cleanup after last generation\n",
    "                print(\"🧹 Cleaning up memory for next generation...\")\n",
    "                cleanup_memory()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed: {str(e)}\")\n",
    "            results.append((prompt, None, f\"error: {str(e)}\"))\n",
    "            cleanup_memory()  # Always cleanup on error\n",
    "\n",
    "    print(f\"\\n✅ Batch generation completed!\")\n",
    "    print(f\"📊 Results: {sum(1 for r in results if r[2] == 'success')}/{len(results)} successful\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example batch generation\n",
    "sample_batch = [\n",
    "    (\"A cat playing with a ball of yarn in slow motion\", \"fast\", 111),\n",
    "    (\"Ocean waves crashing on a rocky shore at dawn\", \"balanced\", 222),\n",
    "    (\"A hummingbird feeding from colorful flowers\", \"balanced\", 333)\n",
    "]\n",
    "\n",
    "print(\"🎬 Example batch ready to run!\")\n",
    "print(\"📝 Uncomment the line below to start batch generation:\")\n",
    "print(\"# batch_results = batch_generate_videos(sample_batch)\")\n",
    "\n",
    "# Uncomment to run:\n",
    "# batch_results = batch_generate_videos(sample_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4431ed95",
   "metadata": {
    "id": "export-header"
   },
   "source": [
    "## 💾 9. Export & Download\n",
    "\n",
    "Export your generated videos to Google Drive or download them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309703c",
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive for permanent storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def copy_to_drive(video_path: str, drive_folder: str = \"HunyuanVideo_Outputs\"):\n",
    "    \"\"\"Copy generated video to Google Drive.\"\"\"\n",
    "    import shutil\n",
    "\n",
    "    drive_path = f\"/content/drive/MyDrive/{drive_folder}\"\n",
    "    os.makedirs(drive_path, exist_ok=True)\n",
    "\n",
    "    filename = os.path.basename(video_path)\n",
    "    drive_file = os.path.join(drive_path, filename)\n",
    "\n",
    "    shutil.copy2(video_path, drive_file)\n",
    "    print(f\"✅ Video copied to Google Drive: {drive_file}\")\n",
    "    return drive_file\n",
    "\n",
    "def download_video(video_path: str):\n",
    "    \"\"\"Download video to local machine.\"\"\"\n",
    "    from google.colab import files\n",
    "    if os.path.exists(video_path):\n",
    "        files.download(video_path)\n",
    "        print(f\"⬇️ Download started for: {os.path.basename(video_path)}\")\n",
    "    else:\n",
    "        print(f\"❌ File not found: {video_path}\")\n",
    "\n",
    "print(\"💾 Google Drive mounted successfully!\")\n",
    "print(\"📁 Use copy_to_drive(video_path) to save to Drive\")\n",
    "print(\"⬇️ Use download_video(video_path) to download directly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076d7ab",
   "metadata": {
    "id": "list-generated"
   },
   "outputs": [],
   "source": [
    "# List all generated videos\n",
    "import glob\n",
    "\n",
    "video_dirs = [\"/content/videos\", \"/content/batch_videos\"]\n",
    "all_videos = []\n",
    "\n",
    "for video_dir in video_dirs:\n",
    "    if os.path.exists(video_dir):\n",
    "        videos = glob.glob(os.path.join(video_dir, \"*.mp4\"))\n",
    "        all_videos.extend(videos)\n",
    "\n",
    "if all_videos:\n",
    "    print(f\"🎬 Found {len(all_videos)} generated videos:\")\n",
    "    for i, video_path in enumerate(all_videos, 1):\n",
    "        file_size = os.path.getsize(video_path) / (1024 * 1024)\n",
    "        print(f\"   {i}. {os.path.basename(video_path)} ({file_size:.1f} MB)\")\n",
    "\n",
    "    print(\"\\n💾 Export options:\")\n",
    "    print(\"   # Copy all videos to Google Drive\")\n",
    "    print(\"   for video in all_videos: copy_to_drive(video)\")\n",
    "    print(\"\")\n",
    "    print(\"   # Download specific video (replace index)\")\n",
    "    print(\"   download_video(all_videos[0])  # Downloads first video\")\n",
    "else:\n",
    "    print(\"📭 No videos found. Generate some videos first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb016981",
   "metadata": {
    "id": "export-all"
   },
   "outputs": [],
   "source": [
    "# Quick export all videos to Drive\n",
    "if all_videos:\n",
    "    export_choice = input(\"Export all videos to Google Drive? (y/n): \")\n",
    "    if export_choice.lower() == 'y':\n",
    "        print(\"📤 Exporting all videos to Google Drive...\")\n",
    "        for video_path in all_videos:\n",
    "            try:\n",
    "                copy_to_drive(video_path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Failed to copy {video_path}: {e}\")\n",
    "        print(\"✅ Export completed!\")\n",
    "    else:\n",
    "        print(\"📋 Export skipped. Use copy_to_drive(video_path) for individual files.\")\n",
    "else:\n",
    "    print(\"📭 No videos to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1d6cf",
   "metadata": {
    "id": "troubleshooting-header"
   },
   "source": [
    "## 🔧 10. Troubleshooting & Optimization\n",
    "\n",
    "Common issues and solutions for HunyuanVideo on Colab A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d16262e",
   "metadata": {
    "id": "diagnostics"
   },
   "outputs": [],
   "source": [
    "def run_diagnostics():\n",
    "    \"\"\"Run comprehensive system diagnostics.\"\"\"\n",
    "    print(\"🔍 Running HunyuanVideo Colab Diagnostics...\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # GPU Information\n",
    "    print(\"\\n🖥️ GPU Information:\")\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_props = torch.cuda.get_device_properties(0)\n",
    "        print(f\"   GPU: {gpu_props.name}\")\n",
    "        print(f\"   Total Memory: {gpu_props.total_memory / 1024**3:.1f} GB\")\n",
    "        print(f\"   CUDA Capability: {gpu_props.major}.{gpu_props.minor}\")\n",
    "\n",
    "        # Check if A100\n",
    "        if \"A100\" in gpu_props.name:\n",
    "            print(\"   ✅ A100 GPU detected - optimal for HunyuanVideo\")\n",
    "        else:\n",
    "            print(\"   ⚠️ Non-A100 GPU - may need optimization\")\n",
    "    else:\n",
    "        print(\"   ❌ No GPU available\")\n",
    "\n",
    "    # Memory Status\n",
    "    print_memory_status(\"\\n🧠 Current Memory\")\n",
    "\n",
    "    # Disk Space\n",
    "    print(\"\\n💾 Disk Space:\")\n",
    "    import shutil\n",
    "    total, used, free = shutil.disk_usage(\"/content\")\n",
    "    print(f\"   Total: {total / 1024**3:.1f} GB\")\n",
    "    print(f\"   Used: {used / 1024**3:.1f} GB\")\n",
    "    print(f\"   Free: {free / 1024**3:.1f} GB\")\n",
    "\n",
    "    if free / 1024**3 < 20:\n",
    "        print(\"   ⚠️ Low disk space - may affect model loading\")\n",
    "\n",
    "    # Library Versions\n",
    "    print(\"\\n📚 Library Versions:\")\n",
    "    try:\n",
    "        import diffusers, transformers, torch\n",
    "        print(f\"   PyTorch: {torch.__version__}\")\n",
    "        print(f\"   Diffusers: {diffusers.__version__}\")\n",
    "        print(f\"   Transformers: {transformers.__version__}\")\n",
    "\n",
    "        # Check versions\n",
    "        if diffusers.__version__ >= \"0.33.1\":\n",
    "            print(\"   ✅ Diffusers version supports HunyuanVideo\")\n",
    "        else:\n",
    "            print(\"   ⚠️ Update diffusers: pip install diffusers>=0.33.1\")\n",
    "    except ImportError as e:\n",
    "        print(f\"   ❌ Import error: {e}\")\n",
    "\n",
    "    # Model Status\n",
    "    print(\"\\n🤖 Model Status:\")\n",
    "    try:\n",
    "        # Check if pipe is loaded\n",
    "        if 'pipe' in globals():\n",
    "            print(\"   ✅ HunyuanVideo pipeline loaded\")\n",
    "            print(f\"   Device: {next(pipe.parameters()).device}\")\n",
    "            print(f\"   Dtype: {next(pipe.parameters()).dtype}\")\n",
    "        else:\n",
    "            print(\"   ❌ HunyuanVideo pipeline not loaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Error checking model: {e}\")\n",
    "\n",
    "    print(\"\\n🔧 Optimization Status:\")\n",
    "    print(f\"   TF32 enabled: {torch.backends.cuda.matmul.allow_tf32}\")\n",
    "    print(f\"   cuDNN benchmark: {torch.backends.cudnn.benchmark}\")\n",
    "    print(f\"   Memory fraction: {torch.cuda.get_memory_fraction(0) if torch.cuda.is_available() else 'N/A'}\")\n",
    "\n",
    "def memory_optimization_tips():\n",
    "    \"\"\"Show memory optimization tips.\"\"\"\n",
    "    print(\"💡 Memory Optimization Tips:\")\n",
    "    print(\"=\" * 30)\n",
    "    print(\"\\n🔧 If you get Out of Memory errors:\")\n",
    "    print(\"   1. Use 'fast' quality setting\")\n",
    "    print(\"   2. Reduce num_frames (try 32 instead of 65)\")\n",
    "    print(\"   3. Lower resolution (512x512 instead of 720p)\")\n",
    "    print(\"   4. Restart runtime to clear memory\")\n",
    "    print(\"   5. Run cleanup_memory() between generations\")\n",
    "\n",
    "    print(\"\\n⚡ For better performance:\")\n",
    "    print(\"   1. Use sequential_cpu_offload (already enabled)\")\n",
    "    print(\"   2. Enable VAE tiling (already enabled)\")\n",
    "    print(\"   3. Use FP16 precision (already enabled)\")\n",
    "    print(\"   4. Generate videos one at a time\")\n",
    "    print(\"   5. Close browser tabs to free system RAM\")\n",
    "\n",
    "# Run diagnostics\n",
    "run_diagnostics()\n",
    "memory_optimization_tips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46dd97",
   "metadata": {
    "id": "emergency-cleanup"
   },
   "outputs": [],
   "source": [
    "# Emergency memory cleanup\n",
    "def emergency_cleanup():\n",
    "    \"\"\"Aggressive memory cleanup for emergency situations.\"\"\"\n",
    "    print(\"🚨 Running emergency memory cleanup...\")\n",
    "\n",
    "    # Clear Python variables\n",
    "    if 'pipe' in globals():\n",
    "        print(\"   Clearing pipeline...\")\n",
    "        del pipe\n",
    "\n",
    "    # Garbage collection\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "    # CUDA cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"   CUDA cache cleared\")\n",
    "\n",
    "    # Check memory after cleanup\n",
    "    print_memory_status(\"(After cleanup)\")\n",
    "\n",
    "    print(\"✅ Emergency cleanup completed\")\n",
    "    print(\"💡 You may need to reload the model with the loading cell above\")\n",
    "\n",
    "print(\"🚨 Emergency cleanup function ready\")\n",
    "print(\"📝 Run emergency_cleanup() if you encounter memory issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bda9e0",
   "metadata": {
    "id": "conclusion-header"
   },
   "source": [
    "## 🎉 Conclusion\n",
    "\n",
    "Congratulations! You've successfully set up and used HunyuanVideo on Google Colab A100.\n",
    "\n",
    "### 🎯 What You've Accomplished:\n",
    "- ✅ Loaded a 13B parameter video generation model on Colab\n",
    "- ✅ Optimized for A100 40GB memory constraints\n",
    "- ✅ Generated high-quality videos up to 15 seconds\n",
    "- ✅ Learned memory management for large AI models\n",
    "- ✅ Set up batch generation and export workflows\n",
    "\n",
    "### 🚀 Next Steps:\n",
    "1. **Experiment** with different prompts and quality settings\n",
    "2. **Explore** the full videogenbook library for more models\n",
    "3. **Read** the complete guide: *Hands-On Video Generation with AI*\n",
    "4. **Join** the community: [GitHub Repository](https://github.com/jenochs/video-generation-book)\n",
    "\n",
    "### 🔗 Resources:\n",
    "- **Documentation**: [videogenbook docs](https://github.com/jenochs/video-generation-book)\n",
    "- **HunyuanVideo**: [Model Card](https://huggingface.co/tencent/HunyuanVideo)\n",
    "- **Colab Pro+**: [Upgrade for A100 access](https://colab.research.google.com/signup)\n",
    "\n",
    "### 💡 Tips for Best Results:\n",
    "- Use detailed, descriptive prompts\n",
    "- Include camera movement descriptions\n",
    "- Specify lighting and atmosphere\n",
    "- Experiment with different seeds for variety\n",
    "- Monitor memory usage for stable generation\n",
    "\n",
    "**Happy video generating! 🎬✨**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
