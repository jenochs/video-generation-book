{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "colab-badge"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenochs/video-generation-book/blob/main/notebooks/hunyuan_colab_a100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# HunyuanVideo on Google Colab A100\n",
        "\n",
        "**Generate high-quality videos using Tencent's HunyuanVideo model on Google Colab A100 GPU**\n",
        "\n",
        "\ud83d\ude80 **What you'll learn:**\n",
        "- Run the 13B parameter HunyuanVideo model on Colab A100 (40GB)\n",
        "- Optimize memory usage for large-scale video generation\n",
        "- Generate videos up to 15 seconds with advanced prompting\n",
        "- Export and download high-quality video results\n",
        "\n",
        "\u26a1 **Requirements:**\n",
        "- Google Colab Pro+ with A100 GPU access\n",
        "- ~20-30 minutes for complete setup\n",
        "- Google Drive for video storage (optional)\n",
        "\n",
        "\ud83d\udcda **From the Book:** *Hands-On Video Generation with AI* - Chapter 3: Advanced Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "# Check GPU and configure environment\n",
        "\\!nvidia-smi\n",
        "\n",
        "import os, torch\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "print(f\"\u2705 GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory/1024**3:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-deps"
      },
      "outputs": [],
      "source": [
        "# Install required packages (optimized for Colab)\n",
        "\\!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --upgrade\n",
        "\\!pip install diffusers>=0.33.1 transformers>=4.52.4 --upgrade\n",
        "\\!pip install xformers imageio-ffmpeg accelerate safetensors --upgrade\n",
        "\\!pip install git+https://github.com/jenochs/video-generation-book.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "memory-utils"
      },
      "outputs": [],
      "source": [
        "# Memory monitoring utilities\n",
        "import torch, gc\n",
        "\n",
        "def get_gpu_memory():\n",
        "    if not torch.cuda.is_available(): return {\"total\": 0, \"free\": 0}\n",
        "    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    cached = torch.cuda.memory_reserved() / 1024**3\n",
        "    return {\"total\": total, \"free\": total - cached}\n",
        "\n",
        "def print_memory_status(stage=\"\"):\n",
        "    mem = get_gpu_memory()\n",
        "    print(f\"\ud83e\udde0 GPU Memory {stage}: {mem[\"free\"]:.1f}GB free / {mem[\"total\"]:.1f}GB total\")\n",
        "\n",
        "def cleanup_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "print_memory_status(\"(Initial)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load-model"
      },
      "outputs": [],
      "source": [
        "# Load HunyuanVideo model with A100 optimizations\n",
        "from diffusers import HunyuanVideoPipeline\n",
        "import time\n",
        "\n",
        "print(\"\ud83d\udd04 Loading HunyuanVideo model...\")\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    pipe = HunyuanVideoPipeline.from_pretrained(\n",
        "        \"hunyuanvideo-community/HunyuanVideo\",\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        low_cpu_mem_usage=True\n",
        "    )\n",
        "    \n",
        "    # A100 40GB optimizations\n",
        "    pipe.enable_sequential_cpu_offload()\n",
        "    pipe.vae.enable_tiling()\n",
        "    pipe.vae.enable_slicing()\n",
        "    \n",
        "    try:\n",
        "        pipe.enable_xformers_memory_efficient_attention()\n",
        "        print(\"   \u2705 xFormers enabled\")\n",
        "    except:\n",
        "        print(\"   \u26a0\ufe0f xFormers not available\")\n",
        "    \n",
        "    load_time = time.time() - start_time\n",
        "    print(f\"\u2705 Model loaded in {load_time:.1f}s\")\n",
        "    print_memory_status(\"(After loading)\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\u274c Failed to load: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate-function"
      },
      "outputs": [],
      "source": [
        "# Simple video generation function\n",
        "from IPython.display import Video, display\n",
        "import imageio, numpy as np, os\n",
        "from datetime import datetime\n",
        "\n",
        "os.makedirs(\"/content/videos\", exist_ok=True)\n",
        "\n",
        "def generate_video(prompt, height=544, width=960, frames=32, steps=25, seed=42):\n",
        "    \"\"\"Generate video optimized for A100 40GB\"\"\"\n",
        "    print(f\"\ud83c\udfac Generating: {prompt[:50]}...\")\n",
        "    print(f\"\ud83c\udfaf {width}x{height}, {frames} frames, {steps} steps\")\n",
        "    \n",
        "    try:\n",
        "        result = pipe(\n",
        "            prompt=prompt,\n",
        "            height=height, width=width, num_frames=frames,\n",
        "            guidance_scale=6.0, num_inference_steps=steps,\n",
        "            generator=torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "        )\n",
        "        \n",
        "        # Save video (convert PIL to numpy)\n",
        "        timestamp = datetime.now().strftime(\"%H%M%S\")\n",
        "        output_path = f\"/content/videos/video_{timestamp}.mp4\"\n",
        "        \n",
        "        print(\"\ud83d\udcbe Saving...\")\n",
        "        with imageio.get_writer(output_path, fps=8, codec=\"h264\") as writer:\n",
        "            for frame in result.frames[0]:\n",
        "                frame_array = np.array(frame.convert(\"RGB\"))\n",
        "                writer.append_data(frame_array)\n",
        "        \n",
        "        print(f\"\u2705 Saved: {output_path}\")\n",
        "        return output_path\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Error: {e}\")\n",
        "        cleanup_memory()\n",
        "        raise\n",
        "\n",
        "print(\"\ud83c\udfac Generation function ready\\!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test-generation"
      },
      "outputs": [],
      "source": [
        "# Generate test video\n",
        "video_path = generate_video(\n",
        "    \"A majestic golden eagle soaring over snow-capped mountains at sunset, cinematic\"\n",
        ")\n",
        "\n",
        "# Display result\n",
        "display(Video(video_path, width=600))\n",
        "print_memory_status(\"(After generation)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## \ud83c\udf89 Success\\!\n",
        "\n",
        "You've successfully:\n",
        "- \u2705 Loaded 13B parameter HunyuanVideo on A100\n",
        "- \u2705 Generated high-quality AI video\n",
        "- \u2705 Optimized for 40GB memory constraints\n",
        "\n",
        "### \ud83d\ude80 Try More Prompts:\n",
        "\n",
        "\n",
        "**Happy video generating\\! \ud83c\udfac\u2728**"
      ]
    }
  ]
}