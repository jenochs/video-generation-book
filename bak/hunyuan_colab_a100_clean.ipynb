{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jenochs/video-generation-book/blob/main/notebooks/hunyuan_colab_a100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# HunyuanVideo on Google Colab A100\n",
    "\n",
    "**Generate high-quality videos using Tencent's HunyuanVideo model on Google Colab A100 GPU**\n",
    "\n",
    "🚀 **What you'll learn:**\n",
    "- Run the 13B parameter HunyuanVideo model on Colab A100 (40GB)\n",
    "- Optimize memory usage for large-scale video generation\n",
    "- Generate videos up to 15 seconds with advanced prompting\n",
    "- Export and download high-quality video results\n",
    "\n",
    "⚡ **Requirements:**\n",
    "- Google Colab Pro+ with A100 GPU access\n",
    "- ~20-30 minutes for complete setup\n",
    "- Google Drive for video storage (optional)\n",
    "\n",
    "📚 **From the Book:** *Hands-On Video Generation with AI* - Chapter 3: Advanced Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 🔧 1. Environment Setup & GPU Verification\n",
    "\n",
    "First, let's verify we have an A100 GPU and configure the environment for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu-check"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability and specifications\n",
    "!nvidia-smi\n",
    "\n",
    "# Verify we have A100 access\n",
    "import subprocess\n",
    "result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], \n",
    "                       capture_output=True, text=True)\n",
    "print(\"\\n🖥️ GPU Information:\")\n",
    "gpu_info = result.stdout.strip().split(', ')\n",
    "if len(gpu_info) >= 2:\n",
    "    gpu_name, gpu_memory = gpu_info[0], int(gpu_info[1])\n",
    "    print(f\"   GPU: {gpu_name}\")\n",
    "    print(f\"   Memory: {gpu_memory:,} MB ({gpu_memory/1024:.1f} GB)\")\n",
    "    \n",
    "    if \"A100\" in gpu_name and gpu_memory >= 40000:\n",
    "        print(\"   ✅ Perfect! A100 40GB detected - optimal for HunyuanVideo\")\n",
    "    elif \"A100\" in gpu_name:\n",
    "        print(\"   ⚠️ A100 detected but check memory - may need optimization\")\n",
    "    else:\n",
    "        print(\"   ❌ Warning: A100 GPU recommended for best performance\")\n",
    "        print(\"   💡 Consider upgrading to Colab Pro+ for A100 access\")\n",
    "else:\n",
    "    print(\"   ❌ Unable to detect GPU information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "env-config"
   },
   "outputs": [],
   "source": [
    "# Configure environment for maximum memory efficiency\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Essential memory optimizations for A100 40GB\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # Async for better performance\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # Avoid warnings\n",
    "\n",
    "# Enable optimized math operations\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"🔧 Environment configured for A100 optimization\")\n",
    "print(f\"   PyTorch version: {torch.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"   GPU count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-header"
   },
   "source": [
    "## 📦 2. Install Dependencies\n",
    "\n",
    "Install the latest versions of required libraries optimized for HunyuanVideo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install-pytorch"
   },
   "outputs": [],
   "source": "# Install PyTorch 2.7+ (Colab has 2.1, we need latest for best video generation)\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --upgrade"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install-diffusers"
   },
   "outputs": [],
   "source": "# Install only what we need (some packages already in Colab)\n!pip install diffusers>=0.33.1 --upgrade  # Not in Colab, required for HunyuanVideo\n!pip install transformers>=4.52.4 --upgrade  # Upgrade from Colab's 4.37.2\n!pip install xformers --upgrade  # Critical for memory efficiency, may not be in Colab\n!pip install imageio-ffmpeg  # For video processing, may not be in Colab\n\n# These are usually pre-installed in Colab, but upgrade if needed\n!pip install accelerate safetensors --upgrade"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install-videogenbook"
   },
   "outputs": [],
   "source": "# Install the videogenbook package\n!pip install git+https://github.com/jenochs/video-generation-book.git\n\n# Verify installation and check versions\nimport videogenbook\nimport torch\nimport diffusers\nimport transformers\n\nprint(f\"✅ videogenbook v{videogenbook.__version__} installed successfully\")\nprint(f\"🔧 PyTorch: {torch.__version__}\")\nprint(f\"🤖 Diffusers: {diffusers.__version__}\")  \nprint(f\"📝 Transformers: {transformers.__version__}\")\nprint(f\"🎯 CUDA available: {torch.cuda.is_available()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "memory-header"
   },
   "source": [
    "## 🧠 3. Memory Monitoring & Optimization\n",
    "\n",
    "Set up memory monitoring and configure HunyuanVideo for A100 40GB constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "memory-utils"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from typing import Dict, Any\n",
    "\n",
    "def get_gpu_memory() -> Dict[str, float]:\n",
    "    \"\"\"Get current GPU memory usage in GB.\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return {\"total\": 0, \"used\": 0, \"free\": 0}\n",
    "    \n",
    "    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "    cached = torch.cuda.memory_reserved() / 1024**3\n",
    "    free = total - cached\n",
    "    \n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"allocated\": allocated,\n",
    "        \"cached\": cached,\n",
    "        \"free\": free\n",
    "    }\n",
    "\n",
    "def print_memory_status(stage: str = \"\"):\n",
    "    \"\"\"Print current memory status.\"\"\"\n",
    "    mem = get_gpu_memory()\n",
    "    print(f\"🧠 GPU Memory {stage}:\")\n",
    "    print(f\"   Total: {mem['total']:.1f} GB\")\n",
    "    print(f\"   Allocated: {mem['allocated']:.1f} GB\")\n",
    "    print(f\"   Cached: {mem['cached']:.1f} GB\") \n",
    "    print(f\"   Free: {mem['free']:.1f} GB\")\n",
    "    \n",
    "    # Memory warnings\n",
    "    if mem['free'] < 10:\n",
    "        print(\"   ⚠️ Low memory - consider reducing resolution/frames\")\n",
    "    elif mem['free'] < 20:\n",
    "        print(\"   ✅ Sufficient memory for standard generation\")\n",
    "    else:\n",
    "        print(\"   🚀 Excellent memory - can use higher quality settings\")\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"Cleanup GPU memory.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "# Initial memory check\n",
    "print_memory_status(\"(Initial)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-header"
   },
   "source": [
    "## 🤖 4. Load HunyuanVideo Model\n",
    "\n",
    "Load the HunyuanVideo model with A100-optimized settings for 40GB memory constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-model"
   },
   "outputs": [],
   "source": [
    "from diffusers import HunyuanVideoPipeline\n",
    "import torch\n",
    "import time\n",
    "\n",
    "print(\"🔄 Loading HunyuanVideo model (this may take 5-10 minutes)...\")\n",
    "print(\"📥 Downloading ~26GB of model weights...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Load with aggressive memory optimization for A100 40GB\n",
    "    pipe = HunyuanVideoPipeline.from_pretrained(\n",
    "        \"hunyuanvideo-community/HunyuanVideo\",  # Fixed: Use community diffusers version\n",
    "        torch_dtype=torch.float16,  # Use FP16 for memory efficiency\n",
    "        use_safetensors=True,\n",
    "        # variant=\"fp16\",  # REMOVED: Community model doesn't have fp16 variants\n",
    "        low_cpu_mem_usage=True,     # Minimize CPU memory during loading\n",
    "    )\n",
    "    \n",
    "    print(\"\\n🔧 Applying A100 optimizations...\")\n",
    "    \n",
    "    # Essential memory optimizations for 40GB constraint\n",
    "    pipe.enable_sequential_cpu_offload()  # Most aggressive memory optimization\n",
    "    pipe.vae.enable_tiling()              # Reduce VAE memory usage\n",
    "    pipe.vae.enable_slicing()             # Further VAE optimization\n",
    "    \n",
    "    # Enable memory-efficient attention if available\n",
    "    try:\n",
    "        pipe.enable_xformers_memory_efficient_attention()\n",
    "        print(\"   ✅ xFormers memory-efficient attention enabled\")\n",
    "    except ImportError:\n",
    "        print(\"   ⚠️ xFormers not available - using default attention\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ xFormers setup issue: {e}\")\n",
    "    \n",
    "    # Configure scheduler for memory efficiency\n",
    "    if hasattr(pipe.scheduler, 'enable_low_mem_usage'):\n",
    "        pipe.scheduler.enable_low_mem_usage = True\n",
    "    \n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"\\n✅ HunyuanVideo loaded successfully in {load_time:.1f}s\")\n",
    "    print(\"🎬 Ready for video generation!\")\n",
    "    \n",
    "    print_memory_status(\"(After model loading)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to load HunyuanVideo: {str(e)}\")\n",
    "    print(\"\\n🔍 Troubleshooting steps:\")\n",
    "    print(\"1. Ensure you have A100 GPU access\")\n",
    "    print(\"2. Check available disk space (need ~30GB)\")\n",
    "    print(\"3. Restart runtime and try again\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "generation-header"
   },
   "source": "from IPython.display import Video, display\nimport imageio\nimport numpy as np\nimport os\n\n# Create output directory\nos.makedirs(\"/content/videos\", exist_ok=True)\n\n# Test generation with A100-optimized settings\nprint(\"🎬 Generating test video...\")\nprompt = \"A majestic golden eagle soaring over snow-capped mountains at sunset, cinematic camera movement\"\n\ntry:\n    # Generate with optimized settings for A100 40GB\n    video_frames = pipe(\n        prompt=prompt,\n        height=544,           # Optimized for A100 memory\n        width=960,            # 16:9 aspect ratio\n        num_frames=32,        # Shorter for memory efficiency\n        guidance_scale=6.0,   # Good quality/memory balance\n        num_inference_steps=25,  # Faster generation\n        generator=torch.Generator(device=\"cuda\").manual_seed(42)\n    ).frames[0]\n    \n    # Save video - Convert PIL images to numpy arrays\n    output_path = \"/content/videos/test_video.mp4\"\n    print(\"💾 Saving video...\")\n    \n    with imageio.get_writer(output_path, fps=8, codec='h264') as writer:\n        for frame in video_frames:\n            # Convert PIL Image to numpy array\n            if hasattr(frame, 'convert'):  # PIL Image\n                frame_array = np.array(frame.convert('RGB'))\n            else:  # Already numpy array\n                frame_array = frame\n            writer.append_data(frame_array)\n    \n    print(f\"✅ Video saved to: {output_path}\")\n    \n    # Display the video\n    display(Video(output_path, width=600))\n    \n    print_memory_status(\"(After generation)\")\n    \nexcept Exception as e:\n    print(f\"❌ Generation failed: {str(e)}\")\n    print(\"🔍 Debug info:\")\n    print(f\"   Frame type: {type(video_frames[0]) if 'video_frames' in locals() else 'Not generated'}\")\n    cleanup_memory()\n    raise",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "test-generation"
   },
   "outputs": [],
   "source": "from IPython.display import Video, display\nimport imageio\nimport numpy as np\nimport os\nfrom datetime import datetime\n\n# Create output directory\nos.makedirs(\\\"/content/videos\\\", exist_ok=True)\n\n## 🎬 5. Simple Video Generation Function\n\ndef generate_video_colab(prompt, height=544, width=960, num_frames=32, steps=25, seed=42):\n    \\\"\\\"\\\"Simple video generation function for Colab.\\\"\\\"\\\"\n    \n    print(f\\\"🎬 Generating: {prompt[:60]}...\\\")\n    print(f\\\"🎯 Settings: {width}x{height}, {num_frames} frames, {steps} steps\\\")\\n    \n    try:\n        # Generate video\n        result = pipe(\n            prompt=prompt,\n            height=height,\n            width=width, \n            num_frames=num_frames,\n            guidance_scale=6.0,\n            num_inference_steps=steps,\n            generator=torch.Generator(device=\\\"cuda\\\").manual_seed(seed)\n        )\n        \n        # Extract frames\n        video_frames = result.frames[0]\n        \n        # Save video\n        timestamp = datetime.now().strftime(\\\"%H%M%S\\\")\n        output_path = f\\\"/content/videos/video_{timestamp}.mp4\\\"\n        \n        print(\\\"💾 Saving video...\\\")\n        with imageio.get_writer(output_path, fps=8, codec='h264') as writer:\n            for frame in video_frames:\n                frame_array = np.array(frame.convert('RGB'))\n                writer.append_data(frame_array)\n        \n        print(f\\\"✅ Saved: {output_path}\\\")\n        return output_path\n        \n    except Exception as e:\n        print(f\\\"❌ Error: {e}\\\")\n        cleanup_memory()\n        raise\n\nprint(\\\"🎬 Simple generation function ready!\\\")\nprint(\\\"📝 Usage: video_path = generate_video_colab('your prompt here')\\\")\""
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion-header"
   },
   "source": "# Generate and display a test video\nvideo_path = generate_video_colab(\n    \\\"A majestic golden eagle soaring over snow-capped mountains at sunset, cinematic camera movement\\\"\n)\n\n# Display the video\ndisplay(Video(video_path, width=600))\nprint_memory_status(\\\"(After generation)\\\")\"",
   "outputs": []
  }
 ]
}